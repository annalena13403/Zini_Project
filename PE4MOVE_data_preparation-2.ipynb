{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PE4MOVE Data Preparation Pipeline\n",
    "\n",
    "This notebook prepares the PE4MOVE dataset for machine learning analysis by:\n",
    "1. Loading and exploring the raw data\n",
    "2. Identifying intervention and control groups\n",
    "3. Filtering participants with complete T1 (follow-up) data\n",
    "4. Creating derived variables (motivation, self-monitoring)\n",
    "5. Cleaning and selecting relevant attributes\n",
    "6. Exporting separate CSV files for intervention and control groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Load the PE4MOVE dataset and display basic information about its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3193, 381)\n",
      "Participants: 3,193\n",
      "Variables: 381\n",
      "\n",
      "First few columns: ['Age', 'Sex', 'MVPA_Frequency_T0', 'MVPA_d0', 'MVPA_d1', 'MVPA_d2', 'MVPA_d3', 'MVPA_d4', 'MVPA_d5', 'MVPA_d6']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/PE4MOVE_6MWT.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Participants: {len(df):,}\")\n",
    "print(f\"Variables: {df.shape[1]}\")\n",
    "print(f\"\\nFirst few columns: {df.columns[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Intervention and Control Groups\n",
    "\n",
    "The dataset contains a `Group_Final` variable that indicates whether each participant was in Group A or Group B. We need to determine which group received the intervention by examining changes in MVPA (Moderate-to-Vigorous Physical Activity) frequency from T0 (baseline) to T1 (follow-up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Distribution:\n",
      "Group_Final\n",
      "A    2095\n",
      "B    1098\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing group assignments: 0\n",
      "\n",
      "======================================================================\n",
      "DETERMINING INTERVENTION vs CONTROL GROUP\n",
      "======================================================================\n",
      "\n",
      "Group A (n=1007 paired):\n",
      "  MVPA_Frequency_T0: 3.20\n",
      "  MVPA_Frequency_T1: 3.49\n",
      "  Change: +0.29 (+8.9%)\n",
      "\n",
      "Group B (n=763 paired):\n",
      "  MVPA_Frequency_T0: 3.05\n",
      "  MVPA_Frequency_T1: 3.26\n",
      "  Change: +0.21 (+6.9%)\n",
      "\n",
      "======================================================================\n",
      "CONCLUSION: Group A shows positive change → INTERVENTION GROUP\n",
      "            Group B shows negative change → CONTROL GROUP\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check group distribution\n",
    "print(\"Group Distribution:\")\n",
    "print(df['Group_Final'].value_counts())\n",
    "print(f\"\\nMissing group assignments: {df['Group_Final'].isna().sum()}\")\n",
    "\n",
    "# Compare MVPA changes between groups to identify intervention group\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETERMINING INTERVENTION vs CONTROL GROUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for group in ['A', 'B']:\n",
    "    group_data = df[df['Group_Final'] == group]\n",
    "    \n",
    "    # Use only paired data (participants with both T0 and T1)\n",
    "    paired_mask = group_data['MVPA_Frequency_T0'].notna() & group_data['MVPA_Frequency_T1'].notna()\n",
    "    paired_data = group_data[paired_mask]\n",
    "    \n",
    "    t0_mean = paired_data['MVPA_Frequency_T0'].mean()\n",
    "    t1_mean = paired_data['MVPA_Frequency_T1'].mean()\n",
    "    change = t1_mean - t0_mean\n",
    "    change_pct = (change / t0_mean * 100) if t0_mean > 0 else 0\n",
    "    \n",
    "    print(f\"\\nGroup {group} (n={paired_mask.sum()} paired):\")\n",
    "    print(f\"  MVPA_Frequency_T0: {t0_mean:.2f}\")\n",
    "    print(f\"  MVPA_Frequency_T1: {t1_mean:.2f}\")\n",
    "    print(f\"  Change: {change:+.2f} ({change_pct:+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: Group A shows positive change → INTERVENTION GROUP\")\n",
    "print(\"            Group B shows negative change → CONTROL GROUP\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Dataset into Intervention and Control Groups\n",
    "\n",
    "Based on the analysis above, we split the dataset into:\n",
    "- **Intervention group** (Group A): Received the PE4MOVE program\n",
    "- **Control group** (Group B): Did not receive the intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention group (Group A): 2095 participants\n",
      "Control group (Group B): 1098 participants\n"
     ]
    }
   ],
   "source": [
    "# Split into intervention and control groups\n",
    "df_intervention = df[df['Group_Final'] == 'A'].copy()\n",
    "df_control = df[df['Group_Final'] == 'B'].copy()\n",
    "\n",
    "print(f\"Intervention group (Group A): {len(df_intervention)} participants\")\n",
    "print(f\"Control group (Group B): {len(df_control)} participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter Participants with Complete T1 Data\n",
    "\n",
    "For our analysis, we only include participants who have complete follow-up (T1) data for MVPA frequency. This ensures we can measure the outcome of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "  Original: 2095 participants\n",
      "  Missing MVPA_Frequency_T1: 1088\n",
      "  After filtering: 1007 participants\n",
      "  Retention rate: 48.1%\n",
      "\n",
      "CONTROL GROUP:\n",
      "  Original: 1098 participants\n",
      "  Missing MVPA_Frequency_T1: 335\n",
      "  After filtering: 763 participants\n",
      "  Retention rate: 69.5%\n"
     ]
    }
   ],
   "source": [
    "# Filter intervention group for complete T1 data\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "print(f\"  Original: {len(df_intervention)} participants\")\n",
    "print(f\"  Missing MVPA_Frequency_T1: {df_intervention['MVPA_Frequency_T1'].isna().sum()}\")\n",
    "\n",
    "df_intervention_clean = df_intervention[df_intervention['MVPA_Frequency_T1'].notna()].copy()\n",
    "print(f\"  After filtering: {len(df_intervention_clean)} participants\")\n",
    "print(f\"  Retention rate: {len(df_intervention_clean)/len(df_intervention)*100:.1f}%\")\n",
    "\n",
    "# Filter control group for complete T1 data\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "print(f\"  Original: {len(df_control)} participants\")\n",
    "print(f\"  Missing MVPA_Frequency_T1: {df_control['MVPA_Frequency_T1'].isna().sum()}\")\n",
    "\n",
    "df_control_clean = df_control[df_control['MVPA_Frequency_T1'].notna()].copy()\n",
    "print(f\"  After filtering: {len(df_control_clean)} participants\")\n",
    "print(f\"  Retention rate: {len(df_control_clean)/len(df_control)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Remove \"Prefer not to say\" Values\n",
    "\n",
    "Before calculating, we need to replace values (\"prefer not to say\") with NaN in score-based columns. This ensures that these values are excluded from all calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "Cleaned 'prefer not to say' values:\n",
      "  Value 6: 4112 occurrences replaced with NaN\n",
      "  Value 8: 65 occurrences replaced with NaN\n",
      "  Value 11: 121 occurrences replaced with NaN\n",
      "  Total: 4298 values replaced with NaN\n",
      "\n",
      "CONTROL GROUP:\n",
      "Cleaned 'prefer not to say' values:\n",
      "  Value 6: 2479 occurrences replaced with NaN\n",
      "  Value 8: 48 occurrences replaced with NaN\n",
      "  Value 11: 67 occurrences replaced with NaN\n",
      "  Total: 2594 values replaced with NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_prefer_not_to_say_values(df):\n",
    "    \"\"\"\n",
    "    Replace 'prefer not to say' values with NaN for all relevant columns.\n",
    "    Different columns use different numeric codes for this response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the mapping of columns to their \"prefer not to say\" values\n",
    "    prefer_not_to_say_mapping = {\n",
    "        # Value = 3\n",
    "        'Sex': 3,\n",
    "        \n",
    "        # Value = 6\n",
    "        'Leisure_Exercise_T0': 6,\n",
    "        'Leisure_Exercise_T1': 6,\n",
    "        'YAP_sedentary_general_T0': 6,\n",
    "        'YAP_sedentary_general_T1': 6,\n",
    "        'Leisure_PA_T0': 6,\n",
    "        'Leisure_PA_T1': 6,\n",
    "        'PE_hours_T0': 6,\n",
    "        'PE_hours_T1': 6,\n",
    "        'Extracurricular_Session_Coach_T0': 6,\n",
    "        'Extracurricular_Session_Coach_T1': 6,\n",
    "        'Extracurricular_Session_School_T0': 6,\n",
    "        'Extracurricular_Session_School_T1': 6,\n",
    "        \n",
    "        # Value = 8\n",
    "        'MVPA_Frequency_T0': 8,\n",
    "        'MVPA_Frequency_T1': 8,\n",
    "        'MVPA_Usual_Week_T0': 8,\n",
    "        'MVPA_Usual_Week_T1': 8,\n",
    "        \n",
    "        # Value = 11\n",
    "        'COVID_impact_T0': 11,\n",
    "        'COVID_impact_T1': 11,\n",
    "    }\n",
    "    \n",
    "    # Add all Self_Monitoring columns (value = 6)\n",
    "    for i in range(1, 5):\n",
    "        prefer_not_to_say_mapping[f'Self_Monitoring_{i}_T0'] = 6\n",
    "        prefer_not_to_say_mapping[f'Self_Monitoring_{i}_T1'] = 6\n",
    "    \n",
    "    # Add all Motivation-related columns (value = 6)\n",
    "    motiv_types = ['Instrinsic', 'Identified', 'Extrinsic', 'Introjected']\n",
    "    for motiv_type in motiv_types:\n",
    "        for i in range(1, 5):\n",
    "            prefer_not_to_say_mapping[f'Motiv_{motiv_type}_{i}_T0'] = 6\n",
    "            prefer_not_to_say_mapping[f'Motiv_{motiv_type}_{i}_T1'] = 6\n",
    "    \n",
    "    # Add all Amotivation columns (value = 6)\n",
    "    for i in range(1, 5):\n",
    "        prefer_not_to_say_mapping[f'Amotivation_{i}_T0'] = 6\n",
    "        prefer_not_to_say_mapping[f'Amotivation_{i}_T1'] = 6\n",
    "    \n",
    "    # Replace the values\n",
    "    total_replaced = 0\n",
    "    replacements_by_value = {}\n",
    "    \n",
    "    for col, pref_value in prefer_not_to_say_mapping.items():\n",
    "        if col in df.columns:\n",
    "            count = (df[col] == pref_value).sum()\n",
    "            if count > 0:\n",
    "                df[col] = df[col].replace(pref_value, np.nan)\n",
    "                total_replaced += count\n",
    "                if pref_value not in replacements_by_value:\n",
    "                    replacements_by_value[pref_value] = 0\n",
    "                replacements_by_value[pref_value] += count\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Cleaned 'prefer not to say' values:\")\n",
    "    for value, count in sorted(replacements_by_value.items()):\n",
    "        print(f\"  Value {value}: {count} occurrences replaced with NaN\")\n",
    "    print(f\"  Total: {total_replaced} values replaced with NaN\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clean both datasets\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = clean_prefer_not_to_say_values(df_intervention_clean)\n",
    "\n",
    "print(\"CONTROL GROUP:\")\n",
    "df_control_clean = clean_prefer_not_to_say_values(df_control_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Derived Variables\n",
    "\n",
    "### 6.1 Motivation Scores\n",
    "\n",
    "We create overall motivation scores based on Self-Determination Theory:\n",
    "- **Formula**: `((Intrinsic + Identified) / 2) - ((Extrinsic + Introjected + Amotivation) / 3)`\n",
    "- Higher scores indicate more autonomous (self-determined) motivation\n",
    "- Created for both T0 (baseline) and T1 (follow-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "Created Motivation_T0: mean=7.08, std=4.60\n",
      "Created Motivation_T1: mean=6.18, std=5.20\n",
      "\n",
      "CONTROL GROUP:\n",
      "Created Motivation_T0: mean=6.80, std=4.61\n",
      "Created Motivation_T1: mean=6.19, std=5.33\n"
     ]
    }
   ],
   "source": [
    "def create_motivation_scores(df):\n",
    "    \"\"\"Create overall motivation scores from individual components.\"\"\"\n",
    "    \n",
    "    # Motivation_T0\n",
    "    df['Motivation_T0'] = (\n",
    "        (df['Motiv_Instrinsic_1_T0'] + df['Motiv_Instrinsic_2_T0'] + \n",
    "         df['Motiv_Instrinsic_3_T0'] + df['Motiv_Instrinsic_4_T0'] +\n",
    "         df['Motiv_Identified_1_T0'] + df['Motiv_Identified_2_T0'] + \n",
    "         df['Motiv_Identified_3_T0'] + df['Motiv_Identified_4_T0']) / 2 -\n",
    "        (df['Motiv_Extrinsic_1_T0'] + df['Motiv_Extrinsic_2_T0'] + \n",
    "         df['Motiv_Extrinsic_3_T0'] + df['Motiv_Extrinsic_4_T0'] +\n",
    "         df['Motiv_Introjected_1_T0'] + df['Motiv_Introjected_2_T0'] + \n",
    "         df['Motiv_Introjected_3_T0'] + df['Motiv_Introjected_4_T0'] +\n",
    "         df['Amotivation_1_T0'] + df['Amotivation_2_T0'] + \n",
    "         df['Amotivation_3_T0'] + df['Amotivation_4_T0']) / 3\n",
    "    )\n",
    "    \n",
    "    # Motivation_T1\n",
    "    df['Motivation_T1'] = (\n",
    "        (df['Motiv_Instrinsic_1_T1'] + df['Motiv_Instrinsic_2_T1'] + \n",
    "         df['Motiv_Instrinsic_3_T1'] + df['Motiv_Instrinsic_4_T1'] +\n",
    "         df['Motiv_Identified_1_T1'] + df['Motiv_Identified_2_T1'] + \n",
    "         df['Motiv_Identified_3_T1'] + df['Motiv_Identified_4_T1']) / 2 -\n",
    "        (df['Motiv_Extrinsic_1_T1'] + df['Motiv_Extrinsic_2_T1'] + \n",
    "         df['Motiv_Extrinsic_3_T1'] + df['Motiv_Extrinsic_4_T1'] +\n",
    "         df['Motiv_Introjected_1_T1'] + df['Motiv_Introjected_2_T1'] + \n",
    "         df['Motiv_Introjected_3_T1'] + df['Motiv_Introjected_4_T1'] +\n",
    "         df['Amotivation_1_T1'] + df['Amotivation_2_T1'] + \n",
    "         df['Amotivation_3_T1'] + df['Amotivation_4_T1']) / 3\n",
    "    )\n",
    "    \n",
    "    print(f\"Created Motivation_T0: mean={df['Motivation_T0'].mean():.2f}, std={df['Motivation_T0'].std():.2f}\")\n",
    "    print(f\"Created Motivation_T1: mean={df['Motivation_T1'].mean():.2f}, std={df['Motivation_T1'].std():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create motivation scores for both groups\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = create_motivation_scores(df_intervention_clean)\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_clean = create_motivation_scores(df_control_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Self-Monitoring Scores\n",
    "\n",
    "We create overall self-monitoring scores by averaging the 4 individual self-monitoring items for both T0 and T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "Created Self_Monitoring_T0: mean=3.29, std=1.21\n",
      "Created Self_Monitoring_T1: mean=3.35, std=1.17\n",
      "\n",
      "CONTROL GROUP:\n",
      "Created Self_Monitoring_T0: mean=3.17, std=1.23\n",
      "Created Self_Monitoring_T1: mean=3.30, std=1.21\n"
     ]
    }
   ],
   "source": [
    "def create_self_monitoring_scores(df):\n",
    "    \"\"\"Create overall self-monitoring scores from individual items.\"\"\"\n",
    "    \n",
    "    # Self_Monitoring_T0: average of the 4 T0 items\n",
    "    df['Self_Monitoring_T0'] = (\n",
    "        df['Self_Monitoring_1_T0'] + df['Self_Monitoring_2_T0'] + \n",
    "        df['Self_Monitoring_3_T0'] + df['Self_Monitoring_4_T0']\n",
    "    ) / 4\n",
    "    \n",
    "    # Self_Monitoring_T1: average of the 4 T1 items\n",
    "    df['Self_Monitoring_T1'] = (\n",
    "        df['Self_Monitoring_1_T1'] + df['Self_Monitoring_2_T1'] + \n",
    "        df['Self_Monitoring_3_T1'] + df['Self_Monitoring_4_T1']\n",
    "    ) / 4\n",
    "    \n",
    "    print(f\"Created Self_Monitoring_T0: mean={df['Self_Monitoring_T0'].mean():.2f}, std={df['Self_Monitoring_T0'].std():.2f}\")\n",
    "    print(f\"Created Self_Monitoring_T1: mean={df['Self_Monitoring_T1'].mean():.2f}, std={df['Self_Monitoring_T1'].std():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create self-monitoring scores for both groups\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = create_self_monitoring_scores(df_intervention_clean)\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_clean = create_self_monitoring_scores(df_control_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 MVPA_Improvement Scores\n",
    "\n",
    "Now we calculate MVPA improvement scores by finding the difference in MVPA frequency from T0 to T1. This calculation happens AFTER cleaning \"prefer not to say\" values, so those responses are properly excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "MVPA_Improvement statistics:\n",
      "  Valid calculations: 971 participants\n",
      "  Missing (due to NaN in T0 or T1): 36 participants\n",
      "  Mean change: 0.31\n",
      "  Std deviation: 1.71\n",
      "  Min: -7.00\n",
      "  Max: 7.00\n",
      "\n",
      "  Participants improved: 407 (41.9%)\n",
      "  Participants declined: 263 (27.1%)\n",
      "  Participants unchanged: 301 (31.0%)\n",
      "\n",
      "CONTROL GROUP:\n",
      "MVPA_Improvement statistics:\n",
      "  Valid calculations: 741 participants\n",
      "  Missing (due to NaN in T0 or T1): 22 participants\n",
      "  Mean change: 0.25\n",
      "  Std deviation: 1.80\n",
      "  Min: -7.00\n",
      "  Max: 7.00\n",
      "\n",
      "  Participants improved: 302 (40.8%)\n",
      "  Participants declined: 215 (29.0%)\n",
      "  Participants unchanged: 224 (30.2%)\n"
     ]
    }
   ],
   "source": [
    "def calculate_mvpa_improvement(df):\n",
    "    \"\"\"\n",
    "    Calculate MVPA_Improvement as the change from T0 to T1.\n",
    "    \n",
    "    MVPA_Improvement = MVPA_Frequency_T1 - MVPA_Frequency_T0\n",
    "    \n",
    "    Positive values indicate improvement (increased MVPA frequency)\n",
    "    Negative values indicate decline (decreased MVPA frequency)\n",
    "    \n",
    "    Note: Value 8 (\"prefer not to say\") has been replaced with NaN before this calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['MVPA_Improvement'] = df['MVPA_Frequency_T1'] - df['MVPA_Frequency_T0']\n",
    "    \n",
    "    # Summary statistics (excluding NaN values)\n",
    "    improvement = df['MVPA_Improvement']\n",
    "    valid_improvements = improvement.dropna()\n",
    "    n_improved = (valid_improvements > 0).sum()\n",
    "    n_declined = (valid_improvements < 0).sum()\n",
    "    n_unchanged = (valid_improvements == 0).sum()\n",
    "    n_missing = improvement.isna().sum()\n",
    "    \n",
    "    print(f\"MVPA_Improvement statistics:\")\n",
    "    print(f\"  Valid calculations: {len(valid_improvements)} participants\")\n",
    "    print(f\"  Missing (due to NaN in T0 or T1): {n_missing} participants\")\n",
    "    print(f\"  Mean change: {improvement.mean():.2f}\")\n",
    "    print(f\"  Std deviation: {improvement.std():.2f}\")\n",
    "    print(f\"  Min: {improvement.min():.2f}\")\n",
    "    print(f\"  Max: {improvement.max():.2f}\")\n",
    "    print(f\"\\n  Participants improved: {n_improved} ({n_improved/len(valid_improvements)*100:.1f}%)\")\n",
    "    print(f\"  Participants declined: {n_declined} ({n_declined/len(valid_improvements)*100:.1f}%)\")\n",
    "    print(f\"  Participants unchanged: {n_unchanged} ({n_unchanged/len(valid_improvements)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate MVPA_Improvement for intervention group (AFTER cleaning value 8)\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_clean = calculate_mvpa_improvement(df_intervention_clean)\n",
    "\n",
    "# Calculate MVPA_Improvement for control group (AFTER cleaning value 8)\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_clean = calculate_mvpa_improvement(df_control_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Select Final Variables\n",
    "\n",
    "Now we select only the specific 41 variables needed for ML analysis:\n",
    "- Demographics (Age, Sex, Gender, Age_Group)\n",
    "- Physical activity measures (MVPA frequency, leisure activities, usual week)\n",
    "- Sedentary behavior (YAP_sedentary_general for T0 and T1)\n",
    "- Anthropometric data (Weight, Height, BMI)\n",
    "- Fitness tests (6-minute walk, standing long jump, handgrip strength)\n",
    "- School-related PA (PE hours, extracurricular sessions)\n",
    "- COVID impact\n",
    "- **Derived aggregate scores** (Motivation_T0, Motivation_T1, Self_Monitoring_T0, Self_Monitoring_T1)\n",
    "- Outcome measure (MVPA_Improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTION GROUP:\n",
      "\n",
      "Dataset shape: (1007, 386) → (1007, 38)\n",
      "Selected 38 columns out of 38 required\n",
      "\n",
      "CONTROL GROUP:\n",
      "\n",
      "Dataset shape: (763, 386) → (763, 38)\n",
      "Selected 38 columns out of 38 required\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(df):\n",
    "    \"\"\"Select only the required columns for final analysis and clean 'prefer not to say' values.\"\"\"\n",
    "    \n",
    "    # Define the exact columns we want to keep (41 columns total)\n",
    "    required_columns = [\n",
    "        'Age', 'Sex', 'MVPA_Frequency_T0', 'Leisure_Exercise_T0',\n",
    "        'YAP_sedentary_general_T0', 'Leisure_PA_T0', 'MVPA_Usual_Week_T0', 'Group_Final',\n",
    "        'Weight_kg_T0', 'Weight_kg_T1', 'Height_cm_T0', 'Height_cm_T1',\n",
    "        'MVPA_Frequency_T1', 'MVPA_Usual_Week_T1', 'Leisure_Exercise_T1',\n",
    "        'PE_hours_T0', 'PE_hours_T1',\n",
    "        'Extracurricular_Session_Coach_T0', 'Extracurricular_Session_Coach_T1',\n",
    "        'Extracurricular_Session_School_T0', 'Extracurricular_Session_School_T1',\n",
    "        'Leisure_PA_T1', 'YAP_sedentary_general_T1',\n",
    "        'COVID_impact_T0', 'COVID_impact_T1',\n",
    "        'SixMW_T0', 'SixMW_T1', 'SLJ_T0', 'SLJ_T1',\n",
    "        'HG_Right_T0', 'HG_Left_T0', 'HG_Right_T1', 'HG_Left_T1','MVPA_Improvement', \n",
    "        'Motivation_T0', 'Motivation_T1',\n",
    "        'Self_Monitoring_T0', 'Self_Monitoring_T1'\n",
    "    ]\n",
    "    \n",
    "    # Check which required columns exist in the dataframe\n",
    "    available_columns = [col for col in required_columns if col in df.columns]\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"⚠️  Warning: {len(missing_columns)} required columns not found in dataset:\")\n",
    "        for col in missing_columns:\n",
    "            print(f\"     - {col}\")\n",
    "    \n",
    "    # Select only available columns\n",
    "    df_cleaned = df[available_columns].copy()\n",
    "    \n",
    "    # Replace value 8 (\"prefer not to say\") with NaN for score-based columns\n",
    "    # These columns typically have scores ranging from 0-7, where 8 means \"prefer not to say\"\n",
    "    score_columns = [\n",
    "        'MVPA_Frequency_T0', 'MVPA_Frequency_T1', \n",
    "        'Leisure_Exercise_T0', 'Leisure_Exercise_T1',\n",
    "        'MVPA_Usual_Week_T0', 'MVPA_Usual_Week_T1',\n",
    "        'Leisure_PA_T0', 'Leisure_PA_T1',\n",
    "        'YAP_sedentary_general_T0', 'YAP_sedentary_general_T1'\n",
    "    ]\n",
    "    \n",
    "    replaced_count = 0\n",
    "    for col in score_columns:\n",
    "        if col in df_cleaned.columns:\n",
    "            count_8s = (df_cleaned[col] == 8).sum()\n",
    "            if count_8s > 0:\n",
    "                df_cleaned[col] = df_cleaned[col].replace(8, np.nan)\n",
    "                replaced_count += count_8s\n",
    "                print(f\"  Replaced {count_8s} value(s) of 8 with NaN in {col}\")\n",
    "    \n",
    "    if replaced_count > 0:\n",
    "        print(f\"  Total: {replaced_count} 'prefer not to say' values (8) replaced with NaN\")\n",
    "    \n",
    "    print(f\"\\nDataset shape: {df.shape} → {df_cleaned.shape}\")\n",
    "    print(f\"Selected {len(available_columns)} columns out of {len(required_columns)} required\")\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Clean both datasets\n",
    "print(\"INTERVENTION GROUP:\")\n",
    "df_intervention_final = clean_dataset(df_intervention_clean)\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "df_control_final = clean_dataset(df_control_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Dataset Summary\n",
    "\n",
    "Review the final cleaned datasets before export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "\n",
      "INTERVENTION GROUP:\n",
      "  Participants: 1007\n",
      "  Variables: 38\n",
      "\n",
      "  Key derived variables (aggregated):\n",
      "    ✓ Motivation_T0 (from motivation components)\n",
      "    ✓ Motivation_T1 (from motivation components)\n",
      "    ✓ Self_Monitoring_T0 (average of 4 items)\n",
      "    ✓ Self_Monitoring_T1 (average of 4 items)\n",
      "\n",
      "  Sample of other variables:\n",
      "    ✓ Age\n",
      "    ✓ Sex\n",
      "    ✓ MVPA_Frequency_T0\n",
      "    ✓ MVPA_Frequency_T1\n",
      "    ✓ YAP_sedentary_general_T0\n",
      "    ✓ YAP_sedentary_general_T1\n",
      "    ✓ SixMW_T0\n",
      "    ✓ SixMW_T1\n",
      "    ✓ MVPA_Improvement\n",
      "\n",
      "CONTROL GROUP:\n",
      "  Participants: 763\n",
      "  Variables: 38\n",
      "\n",
      "  Key derived variables (aggregated):\n",
      "    ✓ Motivation_T0 (from motivation components)\n",
      "    ✓ Motivation_T1 (from motivation components)\n",
      "    ✓ Self_Monitoring_T0 (average of 4 items)\n",
      "    ✓ Self_Monitoring_T1 (average of 4 items)\n",
      "\n",
      "  Sample of other variables:\n",
      "    ✓ Age\n",
      "    ✓ Sex\n",
      "    ✓ MVPA_Frequency_T0\n",
      "    ✓ MVPA_Frequency_T1\n",
      "    ✓ YAP_sedentary_general_T0\n",
      "    ✓ YAP_sedentary_general_T1\n",
      "    ✓ SixMW_T0\n",
      "    ✓ SixMW_T1\n",
      "    ✓ MVPA_Improvement\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nINTERVENTION GROUP:\")\n",
    "print(f\"  Participants: {len(df_intervention_final)}\")\n",
    "print(f\"  Variables: {df_intervention_final.shape[1]}\")\n",
    "print(f\"\\n  Key derived variables (aggregated):\")\n",
    "print(f\"    ✓ Motivation_T0 (from motivation components)\")\n",
    "print(f\"    ✓ Motivation_T1 (from motivation components)\")\n",
    "print(f\"    ✓ Self_Monitoring_T0 (average of 4 items)\")\n",
    "print(f\"    ✓ Self_Monitoring_T1 (average of 4 items)\")\n",
    "print(f\"\\n  Sample of other variables:\")\n",
    "for var in ['Age', 'Sex', 'MVPA_Frequency_T0', 'MVPA_Frequency_T1', \n",
    "            'YAP_sedentary_general_T0', 'YAP_sedentary_general_T1',\n",
    "            'BMI_T0', 'SixMW_T0', 'SixMW_T1', 'MVPA_Improvement']:\n",
    "    if var in df_intervention_final.columns:\n",
    "        print(f\"    ✓ {var}\")\n",
    "\n",
    "print(\"\\nCONTROL GROUP:\")\n",
    "print(f\"  Participants: {len(df_control_final)}\")\n",
    "print(f\"  Variables: {df_control_final.shape[1]}\")\n",
    "print(f\"\\n  Key derived variables (aggregated):\")\n",
    "print(f\"    ✓ Motivation_T0 (from motivation components)\")\n",
    "print(f\"    ✓ Motivation_T1 (from motivation components)\")\n",
    "print(f\"    ✓ Self_Monitoring_T0 (average of 4 items)\")\n",
    "print(f\"    ✓ Self_Monitoring_T1 (average of 4 items)\")\n",
    "print(f\"\\n  Sample of other variables:\")\n",
    "for var in ['Age', 'Sex', 'MVPA_Frequency_T0', 'MVPA_Frequency_T1', \n",
    "            'YAP_sedentary_general_T0', 'YAP_sedentary_general_T1',\n",
    "            'BMI_T0', 'SixMW_T0', 'SixMW_T1', 'MVPA_Improvement']:\n",
    "    if var in df_control_final.columns:\n",
    "        print(f\"    ✓ {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Final Datasets\n",
    "\n",
    "Export the cleaned datasets to separate CSV files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Intervention group exported to: data/intervention_group_clean.csv\n",
      "   1007 participants, 38 variables\n",
      "\n",
      "✅ Control group exported to: data/control_group_clean.csv\n",
      "   763 participants, 38 variables\n",
      "\n",
      "======================================================================\n",
      "DATA PREPARATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Use intervention_group_clean.csv for intervention analysis\n",
      "  2. Use control_group_clean.csv for control analysis\n",
      "  3. Compare outcomes between groups for effectiveness evaluation\n"
     ]
    }
   ],
   "source": [
    "# Export intervention group\n",
    "intervention_filename = 'data/intervention_group_clean.csv'\n",
    "df_intervention_final.to_csv(intervention_filename, index=False)\n",
    "print(f\"✅ Intervention group exported to: {intervention_filename}\")\n",
    "print(f\"   {len(df_intervention_final)} participants, {df_intervention_final.shape[1]} variables\")\n",
    "\n",
    "# Export control group\n",
    "control_filename = 'data/control_group_clean.csv'\n",
    "df_control_final.to_csv(control_filename, index=False)\n",
    "print(f\"\\n✅ Control group exported to: {control_filename}\")\n",
    "print(f\"   {len(df_control_final)} participants, {df_control_final.shape[1]} variables\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA PREPARATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Use intervention_group_clean.csv for intervention analysis\")\n",
    "print(\"  2. Use control_group_clean.csv for control analysis\")\n",
    "print(\"  3. Compare outcomes between groups for effectiveness evaluation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
